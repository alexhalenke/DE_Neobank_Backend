# Transactions ELT Pipeline for a Neobank

## Table of Contents
- [Project Goal]
- [Installation]
- [Usage]
- [Features]
- [Future improvements]
- [Code Example]
- [Credits]
  
  
## Project Goal

A neobank gathered data of 2.7 million transactions. In this project we create a ELT pipeline for the data to enable the use of data analytics and visualization. 
The engineering challenges are the following: 
  - Extracting the data from the different data sources (csv files)
  - Storing the data in data warehouse
  - Data modelling according to business requirements
  - Connecting to an interactive Dashboard 
  - Connecting a LLM to the datawarehouse
  - Making the process scalable and auto scheduled


## Installation

Steps to install your project:
  - Step 1:
  - Step 2:
  - Step 3: 
   

## Usage

How to use your project:


## Features

- Feature 1
- Feature 2
- Feature 3


## Future improvements 
  - inject .env with docker compose (https://docs.docker.com/compose/environment-variables/set-environment-variables/)
  - Own usage of OpenAI key
  - Terraform
  - CloudSQL
  - Orchestration of extract and load process
  - CI/CD pipeline
  - Build an API with different endpoints that trigger different dbt commands (https://medium.com/@ivan_toriya/step-by-step-guide-to-run-dbt-in-production-with-google-cloud-platform-fb1f035f3c7b)
    

## Credits  
Following persons have contributed to this project:

Enrico Dainelli
Ikechi Ochulo
Luiggi Navilys
Marlin Akhter
Alexander Halenke


## Code Example

Provide a code sample that demonstrates a key functionality of your project:
```[programming-language]
code block here
